<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI volunteering — Blog</title>
    <style>
      :root {
        color-scheme: light;
        --bg: #f5f6ff;
        --text: #131c34;
        --muted: #5c6784;
        --accent: #6b8bff;
        --border: rgba(19, 28, 52, 0.08);
        font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      }

      body {
        margin: 0;
        padding: 48px 16px 80px;
        background: var(--bg);
        color: var(--text);
      }

      a {
        color: var(--accent);
      }

      .frame {
        max-width: 720px;
        margin: 0 auto;
        background: white;
        border-radius: 28px;
        padding: 36px;
        box-shadow: 0 18px 40px rgba(19, 28, 52, 0.08);
      }

      h1 {
        margin-top: 0;
        font-size: clamp(2.2rem, 5vw, 3rem);
      }

      h2,
      h3 {
        margin-top: 32px;
        color: var(--text);
      }

      p {
        line-height: 1.7;
        color: var(--muted);
      }

      ul {
        color: var(--muted);
        line-height: 1.7;
      }

      .note {
        margin-top: 32px;
        padding-top: 16px;
        border-top: 1px solid var(--border);
        font-size: 0.95rem;
        font-style: italic;
        color: var(--muted);
      }

      .meta {
        font-size: 0.95rem;
        text-transform: uppercase;
        letter-spacing: 0.08em;
        color: var(--accent);
        margin-bottom: 20px;
      }

      .hero-photo {
        margin: 16px 0 28px;
      }

      .hero-photo img {
        width: 100%;
        display: block;
        border-radius: 18px;
        border: 1px solid var(--border);
      }
    </style>
  </head>
  <body>
    <main class="frame">
      <p><a href="../blog.html">← Back to blog</a></p>
      <article>
        <h1>What volunteering taught me about using AI responsibly in legal services</h1>
        <p class="meta">Reflection · 2025</p>
        <figure class="hero-photo">
          <img src="../images/Ulaw Ultra competition.jpg" alt="ULTRA Student Ambassador competition recognition">
        </figure>
        <p>
          When people talk about Legal AI, the conversation often starts with efficiency, innovation, or disruption. My understanding of AI in law started
          somewhere much quieter: sitting with clients at Citizens Advice and Age UK, watching them struggle through benefit forms that were never designed
          with them in mind. Volunteering changed how I think about technology. It taught me that in legal services, how we use AI matters just as much as
          whether we use it.
        </p>

        <h3>Where the idea really came from</h3>
        <p>
          During my volunteering, I regularly saw clients facing applications such as Personal Independence Payment (PIP) or Attendance Allowance (AA). These
          forms are long—often 30 to 50 pages—and written in dense, technical language. For many clients, especially older adults or people with ADHD,
          cognitive difficulties, or limited literacy, the forms are overwhelming. Even understanding what a question is asking can be a challenge, let alone
          answering it accurately.
        </p>
        <p>
          Advisers and trained volunteers typically spend at least three hours helping with a single application. Demand is extremely high. Appointments are
          fully booked, deadlines are tight, and despite everyone’s best efforts, some clients still struggle to get help in time. Seeing this gap between need
          and capacity is what made me start thinking seriously about AI—not as a replacement for people, but as a support.
        </p>

        <h3>The ULTRA competition and my proposal</h3>
        <p>
          This thinking eventually became the basis of my submission to the University of Law ULTRA Student Ambassador Competition, where I was honoured to be
          selected as a runner-up. My proposal explored how AI could support nonprofit organisations like Citizens Advice and Age UK in one specific area:
          helping clients complete benefit applications more accessibly.
        </p>
        <p>
          The idea was simple. If human advisers are trained using structured guidance, case examples, and eligibility rules, then an AI system could be
          trained on the same materials to provide guided assistance, not legal advice. Such a system could:
        </p>
        <ul>
          <li>Suggest possible answers based on client input.</li>
          <li>Guide clients through questions step by step.</li>
          <li>Offer voice-based interaction so clients could speak instead of read.</li>
          <li>Be available outside normal office hours.</li>
        </ul>
        <p>
          This could help reduce waiting times and allow human advisers to focus on clients who need complex judgement, safeguarding support, or emotional
          reassurance.
        </p>

        <h3>Why AI should support, not replace, human advisers</h3>
        <p>
          Volunteering made one thing very clear to me: legal services are not just transactional. Clients often talk about health, finances, family
          breakdowns, or loss of independence. These are sensitive conversations. Human connection matters. AI cannot replace empathy, trust, or professional
          judgement. It should not try to.
        </p>
        <p>
          What AI can do responsibly is take on repetitive, structured tasks—explaining questions, checking consistency, or prompting clients to reflect on
          daily living impacts—so that advisers have more time to listen, think, and support. Used this way, AI becomes a capacity multiplier, not a
          substitute.
        </p>

        <h3>The risks cannot be ignored</h3>
        <p>
          Working in advice services also made me acutely aware of the risks. Handling benefit applications involves extremely sensitive personal data,
          including health conditions and financial circumstances. Any AI system in this space would require robust safeguards around privacy, data security,
          transparency, and accountability.
        </p>
        <p>
          There is also a risk of over-reliance. AI suggestions must never be treated as decisions. Clients must understand that responsibility remains with
          human advisers and with the system’s oversight framework. Responsible Legal AI must be cautious, explainable, and clearly limited in scope.
        </p>

        <h3>Why I chose video—and what it taught me</h3>
        <p>
          For the ULTRA competition, participants could submit either a written document or a video. I chose video on the same day I saw the competition
          announcement. I believed that video would allow me to communicate not just the idea, but the human context behind it. Tone, pacing, and clarity
          mattered as much as content.
        </p>
        <p>
          I planned, filmed, and edited the video myself. Looking back, this choice made a real difference. It allowed me to present my ideas clearly,
          confidently, and accessibly—and the result confirmed that decision. I was also proud to learn that I was the only Chinese international student to
          reach the top ten of the competition. That mattered to me, not just personally, but because it showed that international students can contribute
          meaningful, grounded perspectives to debates about the future of UK legal services.
        </p>

        <h3>What volunteering ultimately taught me</h3>
        <p>
          Volunteering taught me that responsible AI in law does not start with technology. It starts with listening to clients. It starts with understanding
          real constraints. It starts with respect for vulnerability, dignity, and trust.
        </p>
        <p>
          AI has huge potential in legal services, but only if it is designed around people, not processes alone. My experience at Citizens Advice, Age UK, and
          through the ULTRA competition reinforced one belief I carry forward: the most powerful Legal AI is the kind that quietly helps more people be heard,
          understood, and supported—without replacing the humans they rely on.
        </p>
        <p class="note">This blog post by Hongyu Jiang was completed with assistance from ChatGPT (model: GPT 5.2).</p>
      </article>
    </main>
  </body>
</html>
